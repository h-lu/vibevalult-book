---
title: "70%难题：AI的机遇与陷阱"
---

> "人工智能在处理软件的‘偶然复杂性’（重复性、机械性的工作）方面表现出色，而‘本质复杂性’——理解和管理问题内在的复杂性——仍然落在人类的肩上。" - Hacker News 评论者

人工智能辅助编码工具无疑是革命性的。它们能够以惊人的速度生成代码，将一个项目从零推进到“看起来快要完成”的状态。许多开发者发现，AI助手可以帮助他们完成大约 **70%** 的初步解决方案。这听起来像是魔法，对吗？你描述一个功能，AI瞬间生成代码，原型似乎立刻就有了。

然而，现实很快就会到来，这就是我们所说的“**70%难题**”。

#### **1. AI的超能力：偶然复杂性的终结者**

AI在以下方面表现出卓越的能力：

*   **样板代码生成：** 创建项目结构、配置文件、基础的CRUD操作、数据模型等。
*   **常规函数编写：** 实现常见的算法、数据转换、工具函数等，这些代码往往遵循既定的模式和最佳实践。
*   **代码翻译与重构：** 将一种语言的代码转换为另一种，或根据指令进行简单的代码结构调整。
*   **错误排查与解释：** 帮助理解编译错误、运行时异常，并提供可能的解决方案。

这些能力极大地提高了开发效率，将开发者从繁琐、重复的劳动中解放出来。这部分工作，我们称之为软件的“**偶然复杂性**”（Accidental Complexity）。它是由于工具、语言、框架的限制而产生的，并非问题本身的固有复杂性。

#### **2. AI的致命弱点：本质复杂性的无力**

然而，当项目进入“最后30%”时，AI的局限性就显现出来了。这“最后30%”往往是区分一个玩具项目和一个生产级系统的关键，它包含了软件的“**本质复杂性**”（Essential Complexity）。本质复杂性是问题本身固有的、无法消除的复杂性，例如：

*   **理解复杂需求：** AI难以完全理解模糊、矛盾或隐含的业务需求，无法进行深层次的业务逻辑推理。
*   **处理边缘情况与异常：** 真实世界的系统充满了各种异常情况和边界条件，AI生成的代码往往对此考虑不足，导致系统在特定场景下崩溃或行为异常。
*   **架构优化与权衡：** AI无法进行全局性的架构设计，无法在性能、可扩展性、安全性、成本和开发速度之间做出明智的权衡决策。
*   **确保可维护性与可读性：** AI生成的代码可能功能正确，但缺乏人类可读性、不符合团队编码规范，或难以长期维护。
*   **创造性与创新：** AI只能在现有数据的基础上进行组合和预测，它无法发明全新的算法、设计颠覆性的交互模式，或提出前所未有的解决方案。
*   **为决策承担责任：** AI没有意识，无法为它生成的代码可能带来的后果（如安全漏洞、性能瓶颈）承担责任。

正如Peter Yang所观察到的，非工程师在使用AI编码时，常常在完成70%后陷入“**退两步**”的循环：修复一个问题，引入新的bug，再修复，再引入更多问题。这是因为他们缺乏理解问题真正所在的“思维模型”，无法有效审查和约束AI的输出。

#### **3. 演示质量陷阱：从“看起来能跑”到“真正可用”**

AI可以非常快速地构建出令人印象深刻的“演示”（Demo）。在理想的、预设的路径下，这些演示完美运行。但当真实用户开始进行非预期操作时，问题就暴露了：

*   **不友好的错误信息：** 用户看到的是技术性错误，而非可理解的提示。
*   **未处理的边缘情况：** 导致应用崩溃或数据损坏。
*   **可访问性问题：** 忽略了对残障人士的友好设计。
*   **性能问题：** 在真实负载或较慢设备上表现不佳。

这些问题并非低优先级，它们是区分“人们容忍的软件”和“人们喜爱的软件”的关键。创建真正能让用户自助服务的软件，需要一种专注于“打磨”的艺术，这种对细节的关注、同理心和对工艺的深切关怀，是AI目前无法生成的。

**结论：** AI是强大的工具，但它不是万能的。它擅长处理“偶然复杂性”，但“本质复杂性”仍然牢牢地掌握在人类工程师手中。理解这一点，是你在AI时代茁壮成长的第一步。


### **Vibe Check (思考与练习)**

1.  **思考**: 为什么AI在生成“样板代码”和“常规函数”方面表现出色，但在处理“边缘情况”和“架构优化”时却会遇到困难？这背后的根本原因是什么？
    *   **提示**: 思考AI的训练数据来源、其工作原理（模式识别与预测），以及人类思维在抽象、推理和创造方面的优势。
2.  **AI协同**: 尝试让AI为你生成一个你从未接触过的、稍微复杂一点的功能代码（例如，一个简单的图形算法，如“实现一个A*寻路算法”）。然后，故意给它一个不完整的或有歧义的需求（例如，“让它在有障碍物的地图上寻路，但不要告诉它障碍物如何表示”）。观察AI的输出，并思考它在哪些方面可能“幻觉”或“退两步”。
    *   **目的**: 亲身体验AI在面对不确定性或复杂推理时的局限性。
3.  **案例分析**: 回顾你过去遇到的一个bug，它是否属于“70%”的偶然复杂性（例如，拼写错误、API调用参数错误），还是“30%”的本质复杂性（例如，并发死锁、复杂业务逻辑的漏洞）？如果是后者，你认为AI在当时能帮助你解决吗？为什么？
    *   **提示**: 思考解决该bug所需的思维过程，是模式匹配还是深层推理。

